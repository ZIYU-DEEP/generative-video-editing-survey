% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% One-Shot Tuning Text-to-Video
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
@article{wu2022tune,
  title={Tune-A-Video: One-Shot Tuning of Image Diffusion Models for Text-to-Video Generation},
  author={Wu, Jay Zhangjie and Ge, Yixiao and Wang, Xintao and Lei, Weixian and Gu, Yuchao and Hsu, Wynne and Shan, Ying and Qie, Xiaohu and Shou, Mike Zheng},
  journal={arXiv preprint arXiv:2212.11565},
  URL={https://arxiv.org/abs/2212.11565},
  year={2022}
}

@inproceedings{blattmann2023align,
  title={Align your latents: High-resolution video synthesis with latent diffusion models},
  author={Blattmann, Andreas and Rombach, Robin and Ling, Huan and Dockhorn, Tim and Kim, Seung Wook and Fidler, Sanja and Kreis, Karsten},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={22563--22575},
  URL={https://research.nvidia.com/labs/toronto-ai/VideoLDM/},
  year={2023}
}


% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Zero-Shot Tuning Text-to-Video
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
@article{khachatryan2023text2video,
  title={Text2video-zero: Text-to-image diffusion models are zero-shot video generators},
  author={Khachatryan, Levon and Movsisyan, Andranik and Tadevosyan, Vahram and Henschel, Roberto and Wang, Zhangyang and Navasardyan, Shant and Shi, Humphrey},
  journal={arXiv preprint arXiv:2303.13439},
  URL={https://arxiv.org/abs/2303.13439},
  year={2023}
}

@article{qi2023fatezero,
  title={Fatezero: Fusing attentions for zero-shot text-based video editing},
  author={Qi, Chenyang and Cun, Xiaodong and Zhang, Yong and Lei, Chenyang and Wang, Xintao and Shan, Ying and Chen, Qifeng},
  journal={arXiv preprint arXiv:2303.09535},
  URL={https://arxiv.org/abs/2303.09535},
  year={2023}
}

@article{liu2023video,
  title={Video-p2p: Video editing with cross-attention control},
  author={Liu, Shaoteng and Zhang, Yuechen and Li, Wenbo and Lin, Zhe and Jia, Jiaya},
  journal={arXiv preprint arXiv:2303.04761},
  URL={https://arxiv.org/abs/2303.04761},
  year={2023}
}



% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Pretrained Text-to-Video
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
@article{molad2023dreamix,
  title={Dreamix: Video diffusion models are general video editors},
  author={Molad, Eyal and Horwitz, Eliahu and Valevski, Dani and Acha, Alex Rav and Matias, Yossi and Pritch, Yael and Leviathan, Yaniv and Hoshen, Yedid},
  journal={arXiv preprint arXiv:2302.01329},
  URL={https://arxiv.org/abs/2302.01329},
  year={2023}
}

@inproceedings{ge2022long,
  title={Long video generation with time-agnostic vqgan and time-sensitive transformer},
  author={Ge, Songwei and Hayes, Thomas and Yang, Harry and Yin, Xi and Pang, Guan and Jacobs, David and Huang, Jia-Bin and Parikh, Devi},
  booktitle={Computer Vision--ECCV 2022: 17th European Conference, Tel Aviv, Israel, October 23--27, 2022, Proceedings, Part XVII},
  pages={102--118},
  year={2022},
  organization={Springer},
  URL={https://songweige.github.io/projects/tats/}
}



% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Unclassified
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
@article{wang2023gen,
  title={Gen-L-Video: Multi-Text to Long Video Generation via Temporal Co-Denoising},
  author={Wang, Fu-Yun and Chen, Wenshuo and Song, Guanglu and Ye, Han-Jia and Liu, Yu and Li, Hongsheng},
  journal={arXiv preprint arXiv:2305.18264},
  URL={https://arxiv.org/abs/2305.18264},
  year={2023}
}

@article{yang2023rerender,
  title={Rerender A Video: Zero-Shot Text-Guided Video-to-Video Translation},
  author={Yang, Shuai and Zhou, Yifan and Liu, Ziwei and Loy, Chen Change},
  journal={arXiv preprint arXiv:2306.07954},
  URL={https://arxiv.org/abs/2306.07954},
  year={2023}
}

@inproceedings{lee2023shape,
  title={Shape-aware Text-driven Layered Video Editing},
  author={Lee, Yao-Chih and Jang, Ji-Ze Genevieve and Chen, Yi-Ting and Qiu, Elizabeth and Huang, Jia-Bin},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={14317--14326},
  URL={https://openaccess.thecvf.com/content/CVPR2023/html/Lee_Shape-Aware_Text-Driven_Layered_Video_Editing_CVPR_2023_paper.html},
  year={2023}
}


% %%%%%%%%%%%%%%%%%%%%%%%%%%%
% Uncited but may be useful
% %%%%%%%%%%%%%%%%%%%%%%%%%%%
@article{kasten2021layered,
  title={Layered neural atlases for consistent video editing},
  author={Kasten, Yoni and Ofri, Dolev and Wang, Oliver and Dekel, Tali},
  journal={ACM Transactions on Graphics (TOG)},
  volume={40},
  number={6},
  pages={1--12},
  year={2021},
  publisher={ACM New York, NY, USA}
}

